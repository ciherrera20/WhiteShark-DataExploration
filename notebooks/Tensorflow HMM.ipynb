{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42a4a4ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "from geopandas import GeoDataFrame, read_file\n",
    "from shapely.geometry import Point, LineString, Polygon\n",
    "from datetime import datetime, timedelta\n",
    "import movingpandas as mpd\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import scipy.ndimage as ndi\n",
    "# import torch\n",
    "\n",
    "import scipy\n",
    "import numpy as np\n",
    "import tensorflow.compat.v2 as tf\n",
    "tf.enable_v2_behavior()\n",
    "import tensorflow_probability as tfp\n",
    "from tensorflow_probability import distributions as tfd\n",
    "import scipy.stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee72194c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Set the filename\n",
    "# filename = '../data/SharkArray-2020-05-21-thru-05-28.csv'\n",
    "filename = '../data/2020-21-max-3-min-run.csv'\n",
    "\n",
    "# Load shark positions data into a GeoDataFrame\n",
    "shark_gdf = pd.read_csv(filename)\n",
    "shark_gdf['t'] = pd.to_datetime(shark_gdf['DATETIME'])\n",
    "shark_gdf['geometry'] = gpd.points_from_xy(shark_gdf.LON, shark_gdf.LAT)\n",
    "shark_gdf = gpd.GeoDataFrame(shark_gdf)\n",
    "shark_gdf = shark_gdf.set_crs('EPSG:4326')\n",
    "shark_gdf = shark_gdf.set_index('t').tz_localize(None)\n",
    "shark_gdf.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "372a34ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('The dataset contains', shark_gdf.shape[0], 'rows and', shark_gdf.shape[1], 'columns.')\n",
    "print('The column names are:', list(shark_gdf.columns.values))\n",
    "print('The unique transmitter names are:', shark_gdf['TRANSMITTER'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71c8b2fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a random generator\n",
    "rng = np.random.default_rng()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a635775f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create separate trajectories for each shark based on their transmitter ID\n",
    "traj = mpd.TrajectoryCollection(shark_gdf, 'TRANSMITTER').trajectories[0]\n",
    "print(traj)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16a3532c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Get number of points in each trajectory\n",
    "# data = []\n",
    "# for traj in traj_collection:\n",
    "#     data.append([traj.id.split('_')[0], traj.df.shape[0]])\n",
    "# num_points = pd.DataFrame(data, columns=['TRANSMITTER', 'NUM_POSITIONS'])\n",
    "# print(num_points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de479869",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add a timedelta column which is the time between the previous position and the current position\n",
    "n = traj.df.shape[0]\n",
    "timedeltas = [timedelta()] + [traj.df.index[i] - traj.df.index[i - 1] for i in range(1, n)]\n",
    "traj.df['TIMEDELTA'] = timedeltas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80d6f363",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add velocities and headings to each trajectory\n",
    "traj.add_speed()\n",
    "traj.add_direction()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abf52213",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute turning angles\n",
    "def bound_angle_diff(theta_diff):\n",
    "    return ((theta_diff - 180) % 360) - 180\n",
    "\n",
    "n = traj.df.shape[0]\n",
    "turning_angles = [0] + [bound_angle_diff(traj.df['direction'][i + 1] - traj.df['direction'][i]) for i in range(1, n - 1)] + [0]\n",
    "traj.df['turning_angle'] = turning_angles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "627efd88",
   "metadata": {},
   "outputs": [],
   "source": [
    "traj.plot(linestyle='None')\n",
    "plt.title('Longest 3-min run trajectory')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a92c650b",
   "metadata": {},
   "outputs": [],
   "source": [
    "turning_angles = np.radians(np.array(traj.df['turning_angle']))\n",
    "# turning_angles = tfd.VonMises(loc=-1, concentration=0).sample([207]).numpy()\n",
    "print(turning_angles)\n",
    "plt.hist(turning_angles, bins=np.linspace(-np.pi, np.pi, 30))\n",
    "plt.title('Turning angle histogram')\n",
    "plt.xlabel('angle (rad)')\n",
    "plt.ylabel('counts')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "315f7551",
   "metadata": {},
   "outputs": [],
   "source": [
    "pos_angles = [angle for angle in turning_angles if angle > 0]\n",
    "neg_angles = [angle for angle in turning_angles if angle <= 0]\n",
    "plt.hist(pos_angles, bins=np.linspace(-np.pi, np.pi, 30), alpha=0.8, label='positive angles')\n",
    "plt.hist(neg_angles, bins=np.linspace(-np.pi, np.pi, 30), alpha=0.8, label='negative angles')\n",
    "plt.title('Turning angle histogram')\n",
    "plt.xlabel('angle (rad)')\n",
    "plt.ylabel('counts')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08f677c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot some example von Mises distributions\n",
    "num = 1001\n",
    "locs = [2, 2, 0, 0]\n",
    "cons = [0, 2, 1, 4]\n",
    "x = np.linspace(-np.pi, np.pi, num).reshape(num, 1)\n",
    "y = tfd.VonMises(loc=locs, concentration=cons).prob(x).numpy()\n",
    "for i in range(y.shape[1]):\n",
    "    plt.plot(x[:, 0], y[:, i], label='loc={:.2f}, concentration={:.2f}'.format(locs[i], cons[i]))\n",
    "plt.gca().set_ylim((0, 1))\n",
    "plt.title('Von Mises examples')\n",
    "plt.xlabel('angle (rad)')\n",
    "plt.ylabel('probability density')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87b1a74e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# We assume 2 states\n",
    "num_states = 2\n",
    "\n",
    "# Randomly initialize the initial state distriubtion as well as the transition probabilities\n",
    "initial_probs = tf.Variable(scipy.special.softmax(rng.random([num_states])), name='initial_probs')\n",
    "transition_probs = tf.Variable(scipy.special.softmax(rng.random([num_states, num_states]), axis=1), name='transition_probs')\n",
    "\n",
    "print(\"Initial state probs:\\n{}\".format(initial_probs))\n",
    "print(\"Transition matrix:\\n{}\".format(transition_probs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8768248",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize locations and concentrations of Von Mises distributions for turning angles\n",
    "vm_locs = tf.Variable(np.zeros(num_states))\n",
    "vm_cons = tf.Variable(np.zeros(num_states))\n",
    "\n",
    "print('von Mises locations:\\n{}'.format(vm_locs))\n",
    "print('von Mises concentrations:\\n{}'.format(vm_cons))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c55cb315",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create HMM\n",
    "hmm = tfd.HiddenMarkovModel(\n",
    "    initial_distribution = tfd.Categorical(probs=initial_probs),\n",
    "    transition_distribution = tfd.Categorical(probs=transition_probs),\n",
    "    observation_distribution = tfd.VonMises(loc=vm_locs, concentration=vm_cons),\n",
    "    num_steps = len(turning_angles)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fc223b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a loss function\n",
    "def log_prob():\n",
    "    return tf.reduce_logsumexp(hmm.log_prob(turning_angles))\n",
    "\n",
    "# Define an optimizer to perform back propagation\n",
    "optimizer = tf.keras.optimizers.Adam(learning_rate=0.1)\n",
    "\n",
    "# Make sure probabilities sum to 1\n",
    "def normalize_probs(probs):\n",
    "    abs_probs = tf.math.abs(probs)\n",
    "    if len(probs.shape) > 1:\n",
    "        sums = tf.reshape(tf.reduce_sum(abs_probs, axis=1), [probs.shape[0], 1])\n",
    "    else:\n",
    "        sums = tf.reduce_sum(abs_probs)\n",
    "    return abs_probs / sums\n",
    "\n",
    "def wrap_to_pi(A):\n",
    "    return ((A - np.pi) % (2 * np.pi) - np.pi)\n",
    "\n",
    "# Run a step of the optimizer\n",
    "@tf.function(autograph=False)\n",
    "def train_op():\n",
    "    with tf.GradientTape() as tape:\n",
    "        neg_log_prob = -log_prob()\n",
    "    vars = [initial_probs, transition_probs, vm_locs, vm_cons]\n",
    "    grads = tape.gradient(neg_log_prob, vars)\n",
    "    optimizer.apply_gradients(zip(grads, vars))\n",
    "    initial_probs.assign(normalize_probs(initial_probs))\n",
    "    transition_probs.assign(normalize_probs(transition_probs))\n",
    "    vm_locs.assign(wrap_to_pi(vm_locs))\n",
    "    vm_cons.assign(tf.math.abs(vm_cons))\n",
    "    return neg_log_prob, *vars"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f50fcf6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train on the observations\n",
    "loss_history = []\n",
    "for step in range(201):\n",
    "    loss, ip, tp, vl, vc = [t.numpy() for t in train_op()]\n",
    "    loss_history.append(loss)\n",
    "    if step % 20 == 0:\n",
    "        print(\"step {}: log prob {}\\nInitial probs: {}\\nTransition probs:\\n{}\\nVon Mises locs: {}\\nVon Mises cons: {}\\n\".format(step, -loss, ip, tp, vl, vc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b81adf24",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(loss_history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e26e1777",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot von Mises distributions\n",
    "num = 1001\n",
    "x = np.linspace(-np.pi, np.pi, num).reshape(num, 1)\n",
    "y = hmm.observation_distribution.prob(x).numpy()\n",
    "for i in range(y.shape[1]):\n",
    "    plt.plot(x[:, 0], y[:, i], label='state {}, loc={:.2f}, concentration={:.2f}'.format(i, vm_locs[i], vm_cons[i]))\n",
    "plt.gca().set_ylim((0, 1))\n",
    "plt.title('Emission probability distributions')\n",
    "plt.xlabel('angle (rad)')\n",
    "plt.ylabel('probability density')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b64036f",
   "metadata": {},
   "outputs": [],
   "source": [
    "posterior_dists = hmm.posterior_marginals(turning_angles)\n",
    "posterior_probs = posterior_dists.probs_parameter().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a776f9ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_state_posterior(ax, state_posterior_probs, observed_data, title, label='turning angles', ylabel='angle (rad)'):\n",
    "    ln1 = ax.plot(state_posterior_probs, c='blue', lw=3, label='p(state | angles)')\n",
    "    ax.set_ylim(0., 1.1)\n",
    "    ax.set_ylabel('posterior probability')\n",
    "    ax2 = ax.twinx()\n",
    "    ln2 = ax2.plot(observed_data, c='black', alpha=0.3, label=label)\n",
    "    ax2.set_title(title)\n",
    "    ax2.set_ylabel(ylabel)\n",
    "    lns = ln1 + ln2\n",
    "    labs = [l.get_label() for l in lns]\n",
    "    ax.legend(lns, labs, loc=4)\n",
    "    ax.grid(True, color='white')\n",
    "    ax2.grid(False)\n",
    "\n",
    "fig, axs = plt.subplots(num_states, 1, figsize=(7, 5 * num_states))\n",
    "for state in range(num_states):\n",
    "    plot_state_posterior(axs[state], posterior_probs[:, state], turning_angles, 'state {} (mean turning angle {:.2f} rad)'.format(state, vm_locs[state]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63d5d4a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = [point.coords[0][0] for point in traj.df['geometry']]\n",
    "y = [point.coords[0][1] for point in traj.df['geometry']]\n",
    "fig, ax = plt.subplots(figsize=(10, 10))\n",
    "cmaplist = ['#1f77b4', '#ff7f0e', '#2ca02c', '#d62728', '#9467bd', '#8c564b', '#e377c2', '#7f7f7f', '#bcbd22', '#17becf'][:num_states]\n",
    "cmap = mpl.colors.LinearSegmentedColormap.from_list('Custom cmap', cmaplist, num_states)\n",
    "color = np.argmax(posterior_probs, axis=1)\n",
    "sc = ax.scatter(x, y, c=color, cmap=cmap)\n",
    "traj.df['state'] = color\n",
    "traj.plot(ax=ax, marker='o', column='state', cmap=cmap)\n",
    "ticks = np.array(list(range(num_states)))\n",
    "tick_labels = ['state {}'.format(i) for i in range(num_states)]\n",
    "cbar = plt.colorbar(sc, fraction=0.03)\n",
    "cbar.set_ticks(ticks)\n",
    "cbar.set_ticklabels(tick_labels)\n",
    "plt.title('Trajectory with states')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3660a845",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save to csv with states\n",
    "traj.df.to_csv('../data/2020-21-max-3-min-run-{}-states.csv'.format(num_states), index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54726ca5",
   "metadata": {},
   "outputs": [],
   "source": [
    "speeds = np.array(traj.df['speed'])\n",
    "print(speeds, len(speeds))\n",
    "plt.hist(speeds, bins=np.linspace(0, np.ceil(np.max(speeds)), 30))\n",
    "plt.title('Speed histogram')\n",
    "plt.xlabel('speed (m/s)')\n",
    "plt.ylabel('counts')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d116fef3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We assume 2 states\n",
    "num_states = 2\n",
    "\n",
    "# Randomly initialize the initial state distriubtion as well as the transition probabilities\n",
    "initial_probs = tf.Variable(scipy.special.softmax(rng.random([num_states])), name='initial_probs')\n",
    "transition_probs = tf.Variable(scipy.special.softmax(rng.random([num_states, num_states]), axis=1), name='transition_probs')\n",
    "\n",
    "print(\"Initial state probs:\\n{}\".format(initial_probs))\n",
    "print(\"Transition matrix:\\n{}\".format(transition_probs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddb44d5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot some example gamma distributions\n",
    "num = 1001\n",
    "shapes = [1, 1, 1, 2, 2, 2]\n",
    "rates = [2, 1, 0.5, 2, 1, 0.5]\n",
    "x = np.linspace(0, 6, num).reshape(num, 1)\n",
    "y = tfd.Gamma(concentration=shapes, rate=rates).prob(x).numpy()\n",
    "for i in range(y.shape[1]):\n",
    "    plt.plot(x[:, 0], y[:, i], label='shape={:.2f}, rate={:.2f}'.format(shapes[i], rates[i]))\n",
    "plt.gca().set_xlim((0, 6))\n",
    "plt.gca().set_ylim((0, np.max(y)))\n",
    "plt.title('Gamma examples')\n",
    "plt.xlabel('speed (m/s)')\n",
    "plt.ylabel('probability density')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eaf3d2f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize locations and concentrations of Von Mises distributions for turning angles\n",
    "# vm_locs = tf.Variable(np.zeros(num_states))\n",
    "# vm_cons = tf.Variable(np.zeros(num_states))\n",
    "vm_locs = tf.Variable(rng.random(num_states))\n",
    "vm_cons = tf.Variable(rng.random(num_states))\n",
    "\n",
    "# Initialize shapes and rates of Gamma distributions for step length\n",
    "gamma_shapes = tf.Variable(np.ones(num_states))\n",
    "gamma_rates = tf.Variable(np.ones(num_states))\n",
    "# gamma_shapes = tf.Variable(rng.random(num_states))\n",
    "# gamma_rates = tf.Variable(rng.random(num_states))\n",
    "\n",
    "# joint_dists = tfd.JointDistributionSequential([\n",
    "#     tfd.VonMises(loc=vm_locs, concentration=vm_cons),\n",
    "#     tfd.Gamma(concentration=gamma_shapes, rate=gamma_rates)\n",
    "# ])\n",
    "\n",
    "joint_dists = tfd.Blockwise([\n",
    "    tfd.VonMises(loc=vm_locs, concentration=vm_cons),\n",
    "    tfd.Gamma(concentration=gamma_shapes, rate=gamma_rates)\n",
    "])\n",
    "\n",
    "print('von Mises locations:\\n{}'.format(vm_locs))\n",
    "print('von Mises concentrations:\\n{}'.format(vm_cons))\n",
    "print('Gamma shapes:\\n{}'.format(gamma_shapes))\n",
    "print('Gamma rates:\\n{}'.format(gamma_rates))\n",
    "print(joint_dists)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8798784e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create HMM\n",
    "hmm2 = tfd.HiddenMarkovModel(\n",
    "    initial_distribution = tfd.Categorical(probs=initial_probs),\n",
    "    transition_distribution = tfd.Categorical(probs=transition_probs),\n",
    "    observation_distribution = joint_dists,\n",
    "    num_steps = len(turning_angles)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7b348da",
   "metadata": {},
   "outputs": [],
   "source": [
    "hmm2.log_prob(np.array([turning_angles, speeds]).T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69d9655b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a loss function\n",
    "def log_prob():\n",
    "    return tf.reduce_logsumexp(hmm2.log_prob(np.array([turning_angles, speeds]).T))\n",
    "\n",
    "# Define an optimizer to perform back propagation\n",
    "optimizer = tf.keras.optimizers.Adam(learning_rate=0.1)\n",
    "\n",
    "# Make sure probabilities sum to 1\n",
    "def normalize_probs(probs):\n",
    "    abs_probs = tf.math.abs(probs)\n",
    "    if len(probs.shape) > 1:\n",
    "        sums = tf.reshape(tf.reduce_sum(abs_probs, axis=1), [probs.shape[0], 1])\n",
    "    else:\n",
    "        sums = tf.reduce_sum(abs_probs)\n",
    "    return abs_probs / sums\n",
    "\n",
    "def wrap_to_pi(A):\n",
    "    return ((A - np.pi) % (2 * np.pi) - np.pi)\n",
    "\n",
    "# Run a step of the optimizer\n",
    "@tf.function(autograph=False)\n",
    "def train_op():\n",
    "    with tf.GradientTape() as tape:\n",
    "        neg_log_prob = -log_prob()\n",
    "    vars = [initial_probs, transition_probs, vm_locs, vm_cons, gamma_shapes, gamma_rates]\n",
    "    grads = tape.gradient(neg_log_prob, vars)\n",
    "    optimizer.apply_gradients(zip(grads, vars))\n",
    "    initial_probs.assign(normalize_probs(initial_probs))\n",
    "    transition_probs.assign(normalize_probs(transition_probs))\n",
    "    vm_locs.assign(wrap_to_pi(vm_locs))\n",
    "    vm_cons.assign(tf.math.abs(vm_cons))\n",
    "    gamma_shapes.assign(tf.math.abs(gamma_shapes))\n",
    "    gamma_rates.assign(tf.math.abs(gamma_rates))\n",
    "    return (neg_log_prob, *vars), grads"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "613daa6c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Train on the observations\n",
    "loss_history = []\n",
    "for step in range(200):\n",
    "    ts, grads = train_op()\n",
    "    loss, ip, tp, vl, vc, gs, gr = [t.numpy() for t in ts]\n",
    "    loss_history.append(loss)\n",
    "    if step % 20 == 0:\n",
    "        print(\"step {}: log prob {}\\nInitial probs: {}\\nTransition probs:\\n{}\\nVon Mises locs: {}\\nVon Mises cons: {}\\nGamma shapes: {}\\nGamma rates: {}\\n\".format(step, -loss, ip, tp, vl, vc, gs, gr))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fe5e52a",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(loss_history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c60d3365",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(1, 2, figsize=(10, 5))\n",
    "\n",
    "# Plot observation distributions\n",
    "num = 1001\n",
    "x = np.linspace(-np.pi, np.pi, num).reshape(num, 1)\n",
    "for (j, (obs_dist, ax)) in enumerate(zip(hmm2.observation_distribution.distributions, axs)):\n",
    "    y = obs_dist.prob(x).numpy()\n",
    "    for i in range(y.shape[1]):\n",
    "        if j == 0:\n",
    "            label = 'state {}, loc={:.2f}, concentration={:.2f}'.format(i, vm_locs[i], vm_cons[i])\n",
    "            title = 'Turning angle distributions'\n",
    "        else:\n",
    "            label = 'state {}, mean={:.2f}, mode={:.2f}'.format(i, gamma_shapes[i] / gamma_rates[i], (gamma_shapes[i] - 1) / gamma_rates[i])\n",
    "            title = 'Speed distributions'\n",
    "        ax.plot(x[:, 0], y[:, i], label=label)\n",
    "        ax.set_title(title)\n",
    "        ax.legend(loc='upper right')\n",
    "# fig.suptitle('Emission probability distributions')\n",
    "# axs[0].set_title('Emission probability distributions')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d40fdc5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "posterior_dists = hmm2.posterior_marginals(np.array([turning_angles, speeds]).T)\n",
    "posterior_probs = posterior_dists.probs_parameter().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25521b8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(num_states, 2, figsize=(14, 5 * num_states))\n",
    "for state, ax_row in enumerate(axs):\n",
    "    for i, ax in enumerate(ax_row):\n",
    "        if i == 0:\n",
    "            plot_state_posterior(ax, posterior_probs[:, state], turning_angles, 'state {} (mean turning angle {:.2f} rad)'.format(state, vm_locs[state]))\n",
    "        else:\n",
    "            plot_state_posterior(ax, posterior_probs[:, state], speeds, 'state {} (mean speed {:.2f} m/s)'.format(state, gamma_shapes[state] / gamma_rates[state]), label='speed', ylabel='speed (m/s)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b4a17af",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = [point.coords[0][0] for point in traj.df['geometry']]\n",
    "y = [point.coords[0][1] for point in traj.df['geometry']]\n",
    "fig, ax = plt.subplots(figsize=(10, 10))\n",
    "cmaplist = ['#1f77b4', '#ff7f0e', '#2ca02c', '#d62728', '#9467bd', '#8c564b', '#e377c2', '#7f7f7f', '#bcbd22', '#17becf'][:num_states]\n",
    "cmap = mpl.colors.LinearSegmentedColormap.from_list('Custom cmap', cmaplist, num_states)\n",
    "color = np.argmax(posterior_probs, axis=1)\n",
    "sc = ax.scatter(x, y, c=color, cmap=cmap)\n",
    "traj.df['state'] = color\n",
    "traj.plot(ax=ax, marker='o', column='state', cmap=cmap)\n",
    "ticks = np.array(list(range(num_states)))\n",
    "tick_labels = ['state {}'.format(i) for i in range(num_states)]\n",
    "cbar = plt.colorbar(sc, fraction=0.03)\n",
    "cbar.set_ticks(ticks)\n",
    "cbar.set_ticklabels(tick_labels)\n",
    "plt.title('Trajectory with states')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34c7b64b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save to csv with states\n",
    "traj.df.to_csv('../data/2020-21-max-3-min-run-{}-states-with-speeds.csv'.format(num_states), index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c93b7eea",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_sample_traj(sampled_obs, traj):\n",
    "    '''\n",
    "    Converts a sample from an HMM to a trajectory\n",
    "    '''\n",
    "    # Bound angles to [-pi, pi]\n",
    "    def wrap_to_pi(theta):\n",
    "        return ((theta - 180) % 360) - 180\n",
    "    \n",
    "    # Convert sampled observations to x and y positions\n",
    "    sampled_x = [0]\n",
    "    sampled_y = [0]\n",
    "    sampled_angle = [0]\n",
    "    sampled_turning_angle = [sampled_obs[0][0]]\n",
    "    sampled_speed = [sampled_obs[1][0]]\n",
    "    times = np.array([dt.total_seconds() for dt in traj.df['TIMEDELTA']])\n",
    "    for i, (dt, (turning_angle, speed)) in enumerate(zip(times, sampled_obs)):\n",
    "        prev_x = sampled_x[i]\n",
    "        prev_y = sampled_y[i]\n",
    "        prev_angle = sampled_angle[i]\n",
    "        step_length = dt * speed\n",
    "        angle = wrap_to_pi(prev_angle + turning_angle)\n",
    "        x = step_length * np.cos(angle) + prev_x\n",
    "        y = step_length * np.sin(angle) + prev_y\n",
    "        sampled_x.append(x)\n",
    "        sampled_y.append(y)\n",
    "        sampled_angle.append(angle)\n",
    "        sampled_turning_angle.append(turning_angle)\n",
    "        sampled_speed.append(speed)\n",
    "    \n",
    "    # Align the samples' centroids and make them the same scale\n",
    "    sampled_x = np.array(sampled_x)\n",
    "    sampled_y = np.array(sampled_y)\n",
    "    avg_x = np.average(sampled_x)\n",
    "    avg_y = np.average(sampled_y)\n",
    "    sampled_x -= avg_x\n",
    "    sampled_y -= avg_y\n",
    "    actual_x = []\n",
    "    actual_y = []\n",
    "    for point in traj.df['geometry']:\n",
    "        x, y = point.coords[0]\n",
    "        actual_x.append(x)\n",
    "        actual_y.append(y)\n",
    "    actual_x = np.array(actual_x)\n",
    "    actual_y = np.array(actual_y)\n",
    "    avg_x = np.average(actual_x)\n",
    "    avg_y = np.average(actual_y)\n",
    "    actual_range_x = np.max(actual_x) - np.min(actual_x)\n",
    "    actual_range_y = np.max(actual_y) - np.min(actual_y)\n",
    "    sampled_range_x = np.max(sampled_x) - np.min(sampled_x)\n",
    "    sampled_range_y = np.max(sampled_y) - np.min(sampled_y)\n",
    "    sampled_x *= actual_range_x / sampled_range_x\n",
    "    sampled_y *= actual_range_y / sampled_range_y\n",
    "    sampled_x += avg_x\n",
    "    sampled_y += avg_y\n",
    "    data = np.array([sampled_x, sampled_y, sampled_angle, sampled_turning_angle, sampled_speed])\n",
    "    sample_traj = pd.DataFrame(data.T[1:], columns=['LON', 'LAT', 'direction', 'turning_angle', 'speed'])\n",
    "    sample_traj['t'] = traj.df.index\n",
    "    sample_traj['geometry'] = gpd.points_from_xy(sample_traj.LON, sample_traj.LAT)\n",
    "    sample_traj = gpd.GeoDataFrame(sample_traj)\n",
    "    sample_traj = sample_traj.set_crs('EPSG:4326')\n",
    "    sample_traj = sample_traj.set_index('t').tz_localize(None)\n",
    "    return mpd.Trajectory(sample_traj, traj.id + '-sampled')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80de0bb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sample the HMM to get a path\n",
    "sampled_obs = hmm2.sample().numpy()\n",
    "sample_traj = get_sample_traj(sampled_obs, traj)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa6efb39",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "traj.plot(ax=ax, label='actual path', color='#1f77b4')\n",
    "sample_traj.plot(ax=ax, label='sampled path', color='#ff7f0e')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2962a5a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(traj.df['DEPTH'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47d9ee67",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the filename\n",
    "# filename = '../data/SharkArray-2020-05-21-thru-05-28.csv'\n",
    "filename = '../data/SharkArray-01-animals.csv'\n",
    "\n",
    "# Load shark positions data into a GeoDataFrame\n",
    "shark_gdf = pd.read_csv(filename)\n",
    "shark_gdf['t'] = pd.to_datetime(shark_gdf['DATETIME'])\n",
    "shark_gdf['geometry'] = gpd.points_from_xy(shark_gdf.LON, shark_gdf.LAT)\n",
    "shark_gdf = gpd.GeoDataFrame(shark_gdf)\n",
    "shark_gdf = shark_gdf.set_crs('EPSG:4326')\n",
    "shark_gdf = shark_gdf.set_index('t').tz_localize(None)\n",
    "shark_gdf.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c5cc0b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('The dataset contains', shark_gdf.shape[0], 'rows and', shark_gdf.shape[1], 'columns.')\n",
    "print('The column names are:', list(shark_gdf.columns.values))\n",
    "print('The unique transmitter names are:', shark_gdf['TRANSMITTER'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1d325ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create separate trajectories for each shark based on their transmitter ID\n",
    "traj_collection = mpd.TrajectoryCollection(shark_gdf, 'TRANSMITTER')\n",
    "print(traj_collection)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20ca3663",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Count number of data points for each hour\n",
    "total_counts = []\n",
    "\n",
    "for i, traj in enumerate(traj_collection.trajectories):\n",
    "    start_time = traj.df.index.min()\n",
    "    end_time = traj.df.index.max()\n",
    "    delta = end_time - start_time\n",
    "    num_bins = max(int(delta.total_seconds() // (3600)), 1)\n",
    "    counts = np.histogram(\n",
    "        np.array([(traj.df.index[i] - start_time).total_seconds() for i in range(traj.size())]) // (3600), \n",
    "        num_bins,\n",
    "        range=(0, num_bins)\n",
    "    )[0]\n",
    "    print('{}: Start time = {}, number of bins = {}, number of 0 counts = {}'.format(i, start_time, num_bins, np.sum(counts == 0)))\n",
    "    total_counts.append(counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "943ba25c",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(10, 5))\n",
    "ax.plot(total_counts[9])\n",
    "# ax.set_xlim((0, 100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "311ba3fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We assume 2 states\n",
    "num_states = 2\n",
    "\n",
    "# Randomly initialize the initial state distriubtion as well as the transition probabilities\n",
    "initial_probs = tf.Variable(scipy.special.softmax(rng.random([num_states])), name='initial_probs')\n",
    "transition_probs = tf.Variable(scipy.special.softmax(rng.random([num_states, num_states]), axis=1), name='transition_probs')\n",
    "\n",
    "print(\"Initial state probs:\\n{}\".format(initial_probs))\n",
    "print(\"Transition matrix:\\n{}\".format(transition_probs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee990265",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot some example poisson distributions\n",
    "num = 1001\n",
    "rates = [0, 1, 2, 3]\n",
    "x = np.linspace(0, 6, num).reshape(num, 1)\n",
    "# x = np.arange(0, 10).reshape(-1, 1)\n",
    "y = tfd.Poisson(rate=rates).prob(x).numpy()\n",
    "for i in range(y.shape[1]):\n",
    "    plt.plot(x[:, 0], y[:, i], label='rate={:.2f}'.format(rates[i]))\n",
    "plt.gca().set_xlim((0, 6))\n",
    "plt.gca().set_ylim((0, np.max(y)))\n",
    "plt.title('Poisson examples')\n",
    "plt.xlabel('counts')\n",
    "plt.ylabel('probability density')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4f4a0fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize rates of Poisson distributions for counts\n",
    "poisson_rates = tf.Variable(np.ones(num_states))\n",
    "print('Poisson rates:\\n{}'.format(poisson_rates))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8246232",
   "metadata": {},
   "outputs": [],
   "source": [
    "counts = total_counts[0]\n",
    "print(counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "daf3d2cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create HMM\n",
    "hmm3 = tfd.HiddenMarkovModel(\n",
    "    initial_distribution = tfd.Categorical(probs=initial_probs),\n",
    "    transition_distribution = tfd.Categorical(probs=transition_probs),\n",
    "    observation_distribution = tfd.Poisson(rate=poisson_rates),\n",
    "    num_steps = len(counts)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94c86ed6",
   "metadata": {},
   "outputs": [],
   "source": [
    "hmm3.log_prob(counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6312d549",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a loss function\n",
    "def log_prob():\n",
    "    return tf.reduce_logsumexp(hmm3.log_prob(counts))\n",
    "\n",
    "# Define an optimizer to perform back propagation\n",
    "optimizer = tf.keras.optimizers.Adam(learning_rate=0.1)\n",
    "\n",
    "# Make sure probabilities sum to 1\n",
    "def normalize_probs(probs):\n",
    "    abs_probs = tf.math.abs(probs)\n",
    "    if len(probs.shape) > 1:\n",
    "        sums = tf.reshape(tf.reduce_sum(abs_probs, axis=1), [probs.shape[0], 1])\n",
    "    else:\n",
    "        sums = tf.reduce_sum(abs_probs)\n",
    "    return abs_probs / sums\n",
    "\n",
    "# Run a step of the optimizer\n",
    "@tf.function(autograph=False)\n",
    "def train_op():\n",
    "    with tf.GradientTape() as tape:\n",
    "        neg_log_prob = -log_prob()\n",
    "    vars = [initial_probs, transition_probs, poisson_rates]\n",
    "    grads = tape.gradient(neg_log_prob, vars)\n",
    "    optimizer.apply_gradients(zip(grads, vars))\n",
    "    initial_probs.assign(normalize_probs(initial_probs))\n",
    "    transition_probs.assign(normalize_probs(transition_probs))\n",
    "    poisson_rates.assign(tf.math.abs(poisson_rates))\n",
    "    return (neg_log_prob, *vars), grads"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cf3336c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train on the observations\n",
    "loss_history = []\n",
    "for step in range(200):\n",
    "    ts, grads = train_op()\n",
    "    loss, ip, tp, pr = [t.numpy() for t in ts]\n",
    "    loss_history.append(loss)\n",
    "    if step % 20 == 0:\n",
    "        print(\"Grads:\", *[\"\\n{}\".format(g.numpy()) for g in grads])\n",
    "        print(\"step {}: log prob {}\\nInitial probs: {}\\nTransition probs:\\n{}\\nPoisson rates: {}\\n\".format(step, -loss, ip, tp, pr))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c28fbad2",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(loss_history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5f76884",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot Poisson distributions\n",
    "num = 1001\n",
    "x = np.linspace(0, 50, num).reshape(num, 1)\n",
    "y = hmm3.observation_distribution.prob(x).numpy()\n",
    "for i in range(y.shape[1]):\n",
    "    plt.plot(x[:, 0], y[:, i], label='state {}, rate={:.2f}'.format(i, poisson_rates[i]))\n",
    "plt.gca().set_ylim((0, 1))\n",
    "plt.title('Emission probability distributions')\n",
    "plt.xlabel('counts')\n",
    "plt.ylabel('probability density')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad03deab",
   "metadata": {},
   "outputs": [],
   "source": [
    "posterior_dists = hmm3.posterior_marginals(counts)\n",
    "# posterior_probs = posterior_dists.probs_parameter().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f03c9b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(num_states, 1, figsize=(7, 5 * num_states))\n",
    "for state in range(num_states):\n",
    "    plot_state_posterior(axs[state], posterior_probs[:, state], turning_angles, 'state {} (mean turning angle {:.2f} rad)'.format(state, vm_locs[state]))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "shark-research_project",
   "language": "python",
   "name": "shark-research_project"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
