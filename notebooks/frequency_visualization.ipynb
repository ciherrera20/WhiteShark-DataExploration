{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f8cbcee",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "from geopandas import GeoDataFrame, read_file\n",
    "from shapely.geometry import Point, LineString, Polygon\n",
    "from datetime import datetime, timedelta\n",
    "import movingpandas as mpd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import scipy.ndimage as ndi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8622c3ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load receiver array positions\n",
    "receivers_gdf = pd.read_csv('../data/VPS-Station-Locations.csv')\n",
    "receivers_gdf['geometry'] = gpd.points_from_xy(receivers_gdf.Lng, receivers_gdf.Lat)\n",
    "receivers_gdf = gpd.GeoDataFrame(receivers_gdf)\n",
    "receivers_gdf = receivers_gdf.set_crs('EPSG:4326')\n",
    "receivers_gdf.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35e42d85",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the filename\n",
    "# filename = '../data/SharkArray-2020-05-21-thru-05-28.csv'\n",
    "filename = '../data/SharkArray-01-animals.csv'\n",
    "\n",
    "# Load shark positions data into a GeoDataFrame\n",
    "shark_gdf = pd.read_csv(filename)\n",
    "shark_gdf['t'] = pd.to_datetime(shark_gdf['DATETIME'])\n",
    "shark_gdf['geometry'] = gpd.points_from_xy(shark_gdf.LON, shark_gdf.LAT)\n",
    "shark_gdf = gpd.GeoDataFrame(shark_gdf)\n",
    "shark_gdf = shark_gdf.set_crs('EPSG:4326')\n",
    "shark_gdf = shark_gdf.set_index('t').tz_localize(None)\n",
    "shark_gdf.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21576128",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('The dataset contains', shark_gdf.shape[0], 'rows and', shark_gdf.shape[1], 'columns.')\n",
    "print('The column names are:', list(shark_gdf.columns.values))\n",
    "print('The unique transmitter names are:', shark_gdf['TRANSMITTER'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a79e576c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create separate trajectories for each shark based on their transmitter ID\n",
    "traj_collection = mpd.TrajectoryCollection(shark_gdf, 'TRANSMITTER')\n",
    "print(traj_collection)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74281fd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get number of points in each trajectory\n",
    "data = []\n",
    "for traj in traj_collection:\n",
    "    data.append([traj.id.split('_')[0], traj.df.shape[0]])\n",
    "num_points = pd.DataFrame(data, columns=['TRANSMITTER', 'NUM_POSITIONS'])\n",
    "print(num_points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8ec25a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add a timedelta column which is the time between the previous position and the current position\n",
    "for traj in traj_collection.trajectories:\n",
    "    n = traj.df.shape[0]\n",
    "    timedeltas = [timedelta()] + [traj.df.index[i] - traj.df.index[i - 1] for i in range(1, n)]\n",
    "    traj.df['TIMEDELTA'] = timedeltas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "373429cd",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Plot timemap of positions\n",
    "cmap = plt.get_cmap('jet')\n",
    "N = len(traj_collection.trajectories)\n",
    "fig, axs = plt.subplots(N + 1, 1, figsize=(5, 5 * (N + 1)))\n",
    "for i, traj in enumerate(traj_collection.trajectories):\n",
    "    color = cmap(float(i) / N)\n",
    "    seconds = np.array([traj.df['TIMEDELTA'][i].total_seconds() for i in range(1, traj.df.shape[0])])\n",
    "    xcoords = seconds[:-1] / 60\n",
    "    ycoords = seconds[1:] / 60\n",
    "    axs[0].plot(xcoords, ycoords, marker='.', ls='', markerfacecolor=color, markeredgecolor=color, label=traj.id.split('_')[0])\n",
    "    axs[i + 1].plot(xcoords, ycoords, marker='.', ls='', markerfacecolor=color, markeredgecolor=color, label=traj.id.split('_')[0])\n",
    "    axs[i + 1].set_title('Num points: ' + str(len(seconds)))\n",
    "ticks = [1, 3, 10, 60, 600, 1440, 14400]\n",
    "tick_labels = ['1 min', '3 min', '10 min', '1 hr', '10 hr', '1 d', '10 d']\n",
    "for ax in axs:\n",
    "    ax.set_xscale('log')\n",
    "    ax.set_yscale('log')\n",
    "    ax.legend(bbox_to_anchor=(1.04, 1))\n",
    "    ax.set_xlabel('Time since last position')\n",
    "    ax.set_ylabel('Time before next position')\n",
    "    ax.set_xticks(ticks)\n",
    "    ax.set_yticks(ticks)\n",
    "    ax.set_xticklabels(tick_labels)\n",
    "    ax.set_yticklabels(tick_labels)\n",
    "axs[0].set_title('Shark Array 01 Time Map')\n",
    "plt.savefig('../animations/scatter_timemaps_full_dataset', bbox_inches=\"tight\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41eae316",
   "metadata": {},
   "outputs": [],
   "source": [
    "OUTPUT_SCALE = 'log'\n",
    "\n",
    "# Extract a single trajectory\n",
    "seconds = []\n",
    "xcoords = []\n",
    "ycoords = []\n",
    "transform_data = lambda x: np.log10(x / 60)\n",
    "for i, traj in enumerate(traj_collection.trajectories):\n",
    "    seconds += [traj.df['TIMEDELTA'][i].total_seconds() for i in range(1, traj.df.shape[0])]\n",
    "    xcoords += seconds[:-1]\n",
    "    ycoords += seconds[1:]\n",
    "seconds = np.array(seconds)\n",
    "xcoords = transform_data(np.array(xcoords))\n",
    "ycoords = transform_data(np.array(ycoords))\n",
    "\n",
    "# Set up heatmap\n",
    "\n",
    "# smooth\n",
    "bins = 256\n",
    "width = 8\n",
    "\n",
    "# granular\n",
    "# bins = 50\n",
    "# width = 0\n",
    "\n",
    "H = np.zeros((bins, bins))\n",
    "max_diff = transform_data(np.max(seconds))\n",
    "x_heat = (bins - 1) * xcoords / max_diff\n",
    "y_heat = (bins - 1) * ycoords / max_diff\n",
    "for i in range(len(xcoords)):\n",
    "    H[int(x_heat[i]), int(y_heat[i])] += 1\n",
    "H = ndi.gaussian_filter(H, width)\n",
    "\n",
    "if OUTPUT_SCALE == 'log':\n",
    "    # Log scale output\n",
    "    transform_output = lambda x: np.log10(x + 1)\n",
    "    transform_output_inv = lambda x: 10 ** x - 1\n",
    "else:\n",
    "    # Linear output\n",
    "    transform_output = lambda x: x\n",
    "    transform_output_inv = lambda x: x\n",
    "\n",
    "H = transform_output(H.T)\n",
    "\n",
    "# Plot\n",
    "cmap = plt.get_cmap('nipy_spectral_r')\n",
    "fig, ax = plt.subplots(figsize=(5, 5))\n",
    "plt.imshow(H, origin='lower', extent=(0, max_diff, 0, max_diff), cmap=cmap)\n",
    "ax.set_xlim(0, max_diff)\n",
    "ax.set_ylim(0, max_diff)\n",
    "ax.set_xlabel('Time since last position')\n",
    "ax.set_ylabel('Time before next position')\n",
    "ax.set_title('Shark Array 01 Time Map')\n",
    "ticks = transform_data(np.array([1, 2, 3, 10, 60, 600, 1440, 14400]) * 60)\n",
    "tick_labels = ['1 min', '', '3 min', '10 min', '1 hr', '10 hr', '1 d', '10 d']\n",
    "plt.xticks(ticks, tick_labels)\n",
    "plt.yticks(ticks, tick_labels)\n",
    "cbar = plt.colorbar()\n",
    "cbar.set_label('Num positions')\n",
    "\n",
    "# cbar_ticks = transform_output(np.linspace(0, transform_output_inv(np.max(H)), 10))\n",
    "# cbar_tick_labels = ['%.2f' % x for x in transform_output_inv(cbar_ticks)]\n",
    "\n",
    "cbar_ticks = np.linspace(0, np.max(H), 10)\n",
    "cbar_tick_labels = ['%.2f' % x for x in transform_output_inv(cbar_ticks)]\n",
    "\n",
    "cbar.set_ticks(cbar_ticks)\n",
    "cbar.set_ticklabels(cbar_tick_labels)\n",
    "\n",
    "plt.savefig('../animations/heatmap_time_map_full_dataset_smooth', bbox_inches=\"tight\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5832c0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create histogram of position data by day\n",
    "start_time = shark_gdf.index.min()\n",
    "end_time = shark_gdf.index.max()\n",
    "delta = end_time - start_time\n",
    "bins = int(delta.total_seconds() // (3600 * 24))\n",
    "data = np.array([(shark_gdf.index[i] - start_time).total_seconds() for i in range(shark_gdf.shape[0])]) / (3600 * 24)\n",
    "plt.hist(data, bins=bins)\n",
    "# plt.xticks(np.linspace(0, 7, 8) * 24, ['5-21', '5-22', '5-23', '5-24', '5-25', '5-26', '5-27', '5-28'])\n",
    "plt.gca().set_title('Position data histogram')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d4bc35d",
   "metadata": {},
   "outputs": [],
   "source": [
    "start_time = shark_gdf.index.min()\n",
    "end_time = shark_gdf.index.max()\n",
    "delta = end_time - start_time\n",
    "num_bins = int(delta.total_seconds() // (3600 * 24))\n",
    "total_data = []\n",
    "cmap = plt.get_cmap('jet')\n",
    "N = len(traj_collection.trajectories)\n",
    "fig, axs = plt.subplots(N + 1, 1, figsize=(5, 5 * (N + 1)))\n",
    "ax.hist(data, bins=num_bins)\n",
    "total_data = []\n",
    "colors = []\n",
    "labels = []\n",
    "for (i, traj), ax in zip(enumerate(traj_collection.trajectories), axs[1:]):\n",
    "    color = cmap(float(i) / N)\n",
    "    data = np.array([(traj.df.index[i] - start_time).total_seconds() for i in range(traj.size())]) / (3600 * 24)\n",
    "    label = traj.id.split('_')[0]\n",
    "    total_data.append(data)\n",
    "    colors.append(color)\n",
    "    labels.append(label)\n",
    "    ax.hist(data, bins=num_bins, color=color, label=label)\n",
    "    ax.legend(bbox_to_anchor=(1.04, 1))\n",
    "    ax.set_title('Num positions: ' + str(traj.size()))\n",
    "axs[0].hist(total_data, bins=num_bins, color=colors, label=labels, stacked=True, histtype='barstacked')\n",
    "axs[0].legend(bbox_to_anchor=(1.04, 1))\n",
    "\n",
    "# Set the same scale for each plot\n",
    "for ax in axs[1:]:\n",
    "    ax.set_ylim(axs[0].get_ylim())\n",
    "\n",
    "# plt.xticks(np.linspace(0, 7, 8) * 24, ['5-21', '5-22', '5-23', '5-24', '5-25', '5-26', '5-27', '5-28'])\n",
    "axs[0].set_title('Position data histograms')\n",
    "plt.savefig('../animations/position_data_histograms_full_dataset', bbox_inches=\"tight\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d09080c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(seconds / 60, bins = list(range(0, 60)))\n",
    "plt.gca().set_title('Time difference histogram')\n",
    "plt.gca().set_xlabel('minutes')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c63c42e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add velocities and headings to each trajectory\n",
    "for traj in traj_collection.trajectories:\n",
    "    traj.add_speed()\n",
    "    traj.add_direction()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15843644",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute turning angles\n",
    "def bound_angle_diff(theta_diff):\n",
    "    return ((theta_diff - 180) % 360) - 180\n",
    "\n",
    "for traj in traj_collection.trajectories:\n",
    "    n = traj.df.shape[0]\n",
    "    turning_angles = [traj.df['direction'][0]] + [bound_angle_diff(traj.df['direction'][i + 1] - traj.df['direction'][i]) for i in range(1, n - 1)] + [0]\n",
    "    traj.df['turning_angle'] = turning_angles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54f48f4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "traj_collection.trajectories[0].df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5df3f289",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verify turning angle calculation by showing segment of trajectory\n",
    "i = 1\n",
    "traj_collection.trajectories[0].get_linestring_between(traj_collection.trajectories[0].df.index[i - 1], traj_collection.trajectories[0].df.index[i + 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3feee16",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split by observation gap\n",
    "obs_gap_trajs_dict = {}\n",
    "for traj in traj_collection:\n",
    "    obs_gap_trajs_dict[traj.id.split('_')[0]] = mpd.ObservationGapSplitter(traj).split(gap=timedelta(minutes=3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06c2ca97",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print lengths of trajectories\n",
    "obs_gap_lengths_dict = {}\n",
    "data = []\n",
    "for name, obs_gap_trajs in obs_gap_trajs_dict.items():\n",
    "    lengths = np.array([obs_gap_trajs.trajectories[i].size() for i in range(len(obs_gap_trajs.trajectories))])\n",
    "    obs_gap_lengths_dict[name] = lengths\n",
    "    print(name)\n",
    "    print(lengths)\n",
    "    print('max:', np.max(lengths), 'min:', np.min(lengths), 'avg:', '%.2f' % np.average(lengths), 'sum:', np.sum(lengths), 'len:', len(lengths))\n",
    "    idx = np.argmax(lengths)\n",
    "    max_traj = obs_gap_trajs_dict[name].trajectories[idx]\n",
    "    data.append([name, np.max(lengths), max_traj.get_start_time(), max_traj.get_end_time(), np.average(lengths), np.sum(lengths), len(lengths)])\n",
    "obs_gap_lengths_df = pd.DataFrame(data, columns=['TRANSMITTER', 'MAX_LEN', 'MAX_START_TIME', 'MAX_END_TIME', 'AVG', 'SUM', 'NUM'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d8e63c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(obs_gap_lengths_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05d9e392",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.argmax(obs_gap_lengths_dict['2020-21'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2690c295",
   "metadata": {},
   "outputs": [],
   "source": [
    "obs_gap_trajs_dict['2020-21'].trajectories[509].df['TIMEDELTA']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6491935",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "shark-research_project",
   "language": "python",
   "name": "shark-research_project"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
